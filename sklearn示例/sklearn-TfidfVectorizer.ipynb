{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 实例化TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer()\n",
    "tv.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不计算idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 0., 0., 0., 0.],\n",
       "       [0., 2., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"Chinese Beijing Chinese\",\n",
    "         \"Chinese Chinese Shanghai\",\n",
    "         \"Chinese Macao\",\n",
    "         \"Tokyo Japan Chinese\"]\n",
    "tv = TfidfVectorizer(use_idf=False, smooth_idf=None, norm=None)\n",
    "tv_fit = tv.fit_transform(texts)\n",
    "print(tv.get_feature_names())\n",
    "tv_fit.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 向量归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4472136 , 0.89442719, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.89442719, 0.        , 0.        , 0.4472136 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.70710678, 0.        , 0.70710678, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
       "        0.57735027]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(use_idf=False, smooth_idf=False, norm='l2')\n",
    "tv_fit = tv.fit_transform(texts)\n",
    "print(tv.get_feature_names())\n",
    "tv_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4472136 , 0.89442719, 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "from math import pow\n",
    "import numpy as np\n",
    "(1.0/np.sqrt(pow(1.0,2)+pow(2.0,2)))*np.array([1., 2., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算idf，不加平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.38629436, 2.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 2.        , 0.        , 0.        , 2.38629436,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , 2.38629436, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 2.38629436, 0.        , 0.        ,\n",
       "        2.38629436]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(use_idf=True, smooth_idf=False, norm=None)\n",
    "tv_fit = tv.fit_transform(texts)\n",
    "print(tv.get_feature_names())\n",
    "tv_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.386294361119891"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0*(1+log(4/1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0*(1+log(4/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算idf，加入平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.91629073, 2.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 2.        , 0.        , 0.        , 1.91629073,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , 1.91629073, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 1.91629073, 0.        , 0.        ,\n",
       "        1.91629073]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(use_idf=True, smooth_idf=True, norm=None)\n",
    "tv_fit = tv.fit_transform(texts)\n",
    "print(tv.get_feature_names())\n",
    "tv_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.916290731874155"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0*(1+log((4+1)/(1+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 2.0*(1+log((4+1)/(4+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inverse_transform(X)：返回某篇训练文档向量中的非0特征值所对应的特征词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['chinese', 'beijing'], dtype='<U8')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer()\n",
    "tv_fit = tv.fit_transform(texts)\n",
    "tv.inverse_transform(tv_fit[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
